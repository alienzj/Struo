rule prodigal:
    """
    Running prodigal on each genome
    """
    input:
        fasta = lambda wildcards: config['samples'].loc[wildcards.sample, config['fasta_file_path_col']]
    output:
        fna = temp(config['tmp_dir'] + 'prodigal/{sample}.fna'),
        faa = temp(config['tmp_dir'] + 'prodigal/{sample}.faa'),
        gbk = temp(config['tmp_dir'] + 'prodigal/{sample}.gbk')
    params:
        params = config['params']['prodigal']
    resources:
        time = lambda wildcards, attempt: attempt ** 2 * 59,
        mem_gb_pt = lambda wildcards, attempt: attempt * 2 * 8
    conda:
        '../envs/humann2.yaml'
    log:
        log_dir + 'prodigal/{sample}.log'
    benchmark:
        benchmark_dir + 'prodigal/{sample}.txt'
    shell:
        """
        gunzip -c {input.fasta} | \
          prodigal {params.params} \
          -o {output.gbk} -d {output.fna} -a {output.faa} \
          2> {log} 1>&2
        """

def diamond_tmpfs_size(wildcards, attempt):
    """Estimating the /tmp/ dir size required to hold the DB
    """
    db_size = os.stat(config['params']['diamond_db']).st_size / 1e9
    db_size = round(db_size + 1.499, 0) + attempt ** 2
    return int(db_size)

rule diamond:
    """
    Annotating genes via diamond search of UniRef db
    """
    input:
        faa = config['tmp_dir'] + 'prodigal/{sample}.faa',
	dmnd_db = config['params']['diamond_db']
    output:
        hits = temp(config['tmp_dir'] + 'diamond/{sample}_hits.txt')
    params:
        params = config['params']['diamond'],
	cp_db = config['params']['diamond_db_to_mem'],
	tmp_dir = config['tmp_dir'],
	tmp_db = '/var/sge_tmp.$JOB_ID.0/' + os.path.split(config['params']['diamond_db'])[1]
    threads:
        8
    resources:
        time = lambda wildcards, attempt: attempt * 2 * 60 * 12,
        mem_gb_pt = lambda wildcards, attempt: attempt ** 2 * 3 + 1,
	tmpfs = diamond_tmpfs_size
    conda:
        '../envs/humann2.yaml'
    log:
        log_dir + 'diamond/{sample}.log'
    benchmark:
        benchmark_dir + 'diamond/{sample}.txt'
    shell:
        """
        # copying db to tmpfs
        > {log}
        if [ ! -z ${{JOB_ID+x}} ] && [ "{params.cp_db}" == "True" ]; then
          DB="{params.tmp_db}"
          TMPDIR=`dirname {params.tmp_db}`
          echo "Copying db to tmpfs: {input.dmnd_db} ==> $DB" >> {log}
          cp -f {input.dmnd_db} $DB 2>> {log}
        else
          DB="{input.dmnd_db}"
          TMPDIR="{params.tmp_dir}"
          echo "Not copying db to tmpfs" >> {log}
        fi

        # diamond run
        diamond blastp {params.params} \
           -q {input.faa} -d $DB -o {output.hits} \
           --tmpdir $TMPDIR --threads {threads} \
           --outfmt 6 qseqid sseqid pident length qstart qend qlen sstart send slen evalue \
           2>> {log} 1>&2
        """

rule annotate_genes:
    """
    Annotating genes via diamond search of UniRef db
    """
    input:
        hits = config['tmp_dir'] + 'diamond/{sample}_hits.txt',
        fna = config['tmp_dir'] + 'prodigal/{sample}.fna',
        faa = config['tmp_dir'] + 'prodigal/{sample}.faa',
    output:
        fna = temp(config['tmp_dir'] + 'prodigal/{sample}_annot.fna'),
        faa = temp(config['tmp_dir'] + 'prodigal/{sample}_annot.faa')
    params:
        tax = lambda wildcards: config['samples'].loc[wildcards.sample, config['taxonomy_col']],
        taxID = lambda wildcards: config['samples'].loc[wildcards.sample, config['taxID_col']],
        exe = config['pipeline']['script_folder'] + 'annotate_genes.py',
	prefix = config['tmp_dir'] + 'prodigal/{sample}'
    resources:
        time = lambda wildcards, attempt: attempt ** 3 * 59,
        mem_gb_pt = lambda wildcards, attempt: attempt ** 2 * 6
    conda:
        '../envs/humann2.yaml'
    log:
        log_dir + 'annotate_genes/{sample}.log'
    benchmark:
        benchmark_dir + 'annotate_genes/{sample}.txt'
    shell:
        """
        {params.exe} --prefix {params.prefix} \
           --columns qseqid,sseqid,pident,length,qstart,qend,qlen,sstart,send,slen,evalue \
           {input.hits} {input.fna} {input.faa} "{params.tax}" {params.taxID} \
           2> {log} 1>&2
        """

rule cluster_genes_nuc:
    """
    Clustering genes (at nuc level) and taking the centroid. 
    This is done for each sample (genome)
    """
    input:
        fna = config['tmp_dir'] + 'prodigal/{sample}_annot.fna',
        faa = config['tmp_dir'] + 'prodigal/{sample}_annot.faa'
    output:
        reps = temp(config['tmp_dir'] + 'vsearch/{sample}_annot_reps.fna'),
        fna = humann2_dir + 'nuc_filtered/{sample}_annot_reps.fna.gz',
        faa = humann2_dir + 'prot_filtered/{sample}_annot_reps.faa.gz'
    params:
        params = config['params']['vsearch'],
        exe = config['pipeline']['script_folder'] + 'filter_seqs.py'
    threads:
        8
    resources:
        time = lambda wildcards, attempt: attempt ** 2 * 59,
        mem_gb_pt = lambda wildcards, attempt: attempt * 2
    conda:
        '../envs/humann2.yaml'
    log:
        log_dir + 'cluster_genes_nuc/{sample}.log'
    benchmark:
        benchmark_dir + 'cluster_genes_nuc/{sample}.txt'
    shell:
        """
         # cluster
         vsearch {params.params} \
           --threads {threads} \
           --cluster_fast {input.fna} \
           --centroids {output.reps} \
           2> {log} 1>&2

        # filter to just reps (duplicates removed)
        {params.exe} --gzip {output.reps} {input.faa} \
           {output.fna} {output.faa} 2> {log} 1>&2
        """

localrules: cat_genes_nuc

def cat_genes_nuc_input(wcs):
    x = expand(humann2_dir + 'nuc_filtered/{sample}_annot_reps.fna.gz',
               sample = config['samples_unique'])
    if os.path.isfile(config['humann2_nuc_seqs']):
        x.append(config['humann2_nuc_seqs'])
    return(x)
    
rule cat_genes_nuc:
    """
    Combining genes: from genomes & user-provided genes
    """
    input:
        cat_genes_nuc_input
    output:
        temp(config['tmp_dir'] + 'humann2/all_genes_annot.fna')
    log:
        log_dir + 'cat_genes_nuc/all.log'
    benchmark:
        benchmark_dir + 'cat_genes_nuc/all.txt'
    run:
        import os,gzip
        with open(output[0], 'w') as outF:
            for F in input:
                with gzip.open(F, 'rb') as inF:
                    for line in inF:
                        outF.write(line.decode('utf-8'))
                
localrules: cat_genes_prot

def cat_genes_prot_input(wcs):
    x = expand(humann2_dir + 'prot_filtered/{sample}_annot_reps.faa.gz',
               sample = config['samples_unique'])
    if os.path.isfile(config['humann2_prot_seqs']):
        x.append(config['humann2_prot_seqs'])
    return x

rule cat_genes_prot:
    """
    Combining genes: from genomes & user-provided genes
    """
    input:
        cat_genes_prot_input
    output:
        temp(config['tmp_dir'] + 'humann2/all_genes_annot.faa')
    log:
        log_dir + 'cat_genes_AA/all.log'
    benchmark:
        benchmark_dir + 'cat_genes_AA/all.txt'
    run:
        import os,gzip
        with open(output[0], 'w') as outF:
            for F in input:
                with gzip.open(F, 'rb') as inF:
                    for line in inF:
                        outF.write(line.decode('utf-8'))

if config['humann2_nuc_seqs'] != 'Skip' or config['humann2_prot_seqs'] != 'Skip':

    rule cluster_all_genes_nuc:
        """
        Clustering genes (at nuc level) and taking the centroid
        """
        input:
            fna = config['tmp_dir'] + 'humann2/all_genes_annot.fna',
            faa = config['tmp_dir'] + 'humann2/all_genes_annot.faa'
        output:
            reps = temp(config['tmp_dir'] + 'vsearch/all_annot_reps.fna'),
            fna = temp(config['tmp_dir'] + 'humann2/all_genes_annot.fna.gz'),
            faa = temp(config['tmp_dir'] + 'humann2/all_genes_annot.faa.gz')
        params:
            params = config['params']['vsearch'],
            exe = config['pipeline']['script_folder'] + 'filter_seqs.py'
        threads:
            12
        resources:
            time = lambda wildcards, attempt: attempt ** 2 * 59,
            mem_gb_pt = lambda wildcards, attempt: attempt * 2 ** 2
        conda:
            '../envs/humann2.yaml'
        log:
            log_dir + 'cluster_all_genes_nuc/all.log'
        benchmark:
            benchmark_dir + 'cluster_all_genes_nuc/all.txt'
        shell:
            """
             # cluster
             vsearch {params.params} \
               --threads {threads} \
               --cluster_fast {input.fna} \
               --centroids {output.reps} \
               2> {log} 1>&2
    
            # filter to just reps (duplicates removed)
            {params.exe} --gzip {output.reps} {input.faa} \
               {output.fna} {output.faa} 2> {log} 1>&2
            """
else:
    localrules: cluster_all_genes_nuc_SKIP
    
    rule cluster_all_genes_nuc_SKIP:
        """
        Clustering genes (at nuc level) and taking the centroid
        """
        input:
            fna = config['tmp_dir'] + 'humann2/all_genes_annot.fna',
            faa = config['tmp_dir'] + 'humann2/all_genes_annot.faa'
        output:
            fna = temp(config['tmp_dir'] + 'humann2/all_genes_annot.fna.gz'),
            faa = temp(config['tmp_dir'] + 'humann2/all_genes_annot.faa.gz')
        log:
            log_dir + 'cluster_all_genes_nuc/all.log'
        benchmark:
            benchmark_dir + 'cluster_all_genes_nuc/all.txt'
        shell:
            """
            ln -s -f {input.fna} {output.fna} 2> {log}
            ln -s -f {input.faa} {output.faa} 2>> {log}
            """

rule humann2_bowtie2_build:
    """
    Running bowtie2 build on combined, annotated genes 
    """
    input:
        config['tmp_dir'] + 'humann2/all_genes_annot.fna.gz'
    output:
        touch(humann2_dir + 'bowtie2_build.done')
    params:
        prefix = humann2_dir + 'all_genes_annot'
    conda:
        '../envs/humann2.yaml'
    threads:
        24
    resources:
        time = lambda wildcards, attempt: attempt * 2 * 60 * 24,
        mem_gb_pt = lambda wildcards, attempt: attempt ** 2 * 3 + 6
    log:
        log_dir + 'humann2_bowtie2_build/all.log'
    benchmark:
        log_dir + 'humann2_bowtie2_build/all.txt'
    shell:
        """
        bowtie2-build --threads {threads} \
          {input} {params.prefix} 2> {log} 1>&2        

        # check that output exists
        OUTDIR=`dirname {params.prefix}`
        IDX_FILES=`find $OUTDIR -maxdepth 1 -name "*.bt2*"`
        IDX_FILES=`echo $IDX_FILES | perl -pe 's/ +/\n/g' | wc -l`
        if [ $IDX_FILES -lt 1 ]; then
          echo "ERROR: no bowtie2 index files found!"
          exit 1
        fi
        """    

rule humann2_diamond_makedb:
    """
    Running diamond makedb on combined, annotated genes 
    """
    input:
        config['tmp_dir'] + 'humann2/all_genes_annot.faa.gz'
    output:
        humann2_dir + 'all_genes_annot.dmnd'
    params:
        prefix = humann2_dir + 'all_genes_annot',
	tmp_dir = config['tmp_dir']
    conda:
        '../envs/humann2.yaml'
    resources:
        time = lambda wildcards, attempt: attempt * 2 * 60 * 24,
        mem_gb_pt = lambda wildcards, attempt: attempt ** 3 * 12
    log:
        log_dir + 'humann2_diamond_makedb/all.log'
    benchmark:
        log_dir + 'humann2_diamond_makedb/all.txt'
    shell:
        """
        PREF=`echo {output} | perl -pe 's/\.[^.]+$//'`
        diamond makedb --in {input} -d $PREF 2> {log} 1>&2
        """    


